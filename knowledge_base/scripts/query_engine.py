#!/usr/bin/env python3
"""
Omphalina çŸ¥è¯†åº“ â€” æŸ¥è¯¢å¼•æ“

åŸºäº NetworkX å› æœå›¾å’Œå…¨æ™¯çŸ¥è¯†åº“ï¼Œæä¾›æ ¸å¿ƒæŸ¥è¯¢åŠŸèƒ½ï¼š
1. æŒ‰ drama_score æ’åºçš„æ¶Ÿæ¼ªæ•ˆåº”
2. æœ€è®½åˆºçš„å› æœè·¯å¾„
3. è·¨åŒ–åˆç‰©å› æœé“¾å‘ç°
4. ä¸º Gemini prompt æ„å»ºä¸Šä¸‹æ–‡

ç”¨æ³•:
    from query_engine import QueryEngine
    engine = QueryEngine()
    result = engine.most_dramatic_ripples("aspirin", top_n=5)
"""

import os
import glob
import networkx as nx
from typing import Any

# åŒçº§æ¨¡å—å¯¼å…¥
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from graph_builder import load_graph_from_storylines, get_graph_stats

# ============================================================
# é…ç½®
# ============================================================

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
ENCYCLOPEDIA_DIR = os.path.join(BASE_DIR, "encyclopedia", "compounds")


class QueryEngine:
    """
    Omphalina æŸ¥è¯¢å¼•æ“

    æä¾›å› æœå›¾éå†å’ŒçŸ¥è¯†åº“æ£€ç´¢åŠŸèƒ½ï¼Œ
    è¾“å‡ºå¯ç›´æ¥ç”¨äº Gemini prompt çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡ã€‚
    """

    def __init__(self):
        self.graph = load_graph_from_storylines()
        self.stats = get_graph_stats(self.graph)

    def reload(self):
        """é‡æ–°åŠ è½½å›¾æ•°æ®"""
        self.graph = load_graph_from_storylines()
        self.stats = get_graph_stats(self.graph)

    # ========================================================
    # æ ¸å¿ƒæŸ¥è¯¢
    # ========================================================

    def most_dramatic_ripples(self, compound_id: str, top_n: int = 5) -> list[dict]:
        """
        ä»æŒ‡å®šåŒ–åˆç‰©å‡ºå‘ï¼Œæ‰¾åˆ° drama_score æœ€é«˜çš„æ¶Ÿæ¼ªæ•ˆåº”é“¾ã€‚

        è¿”å›:
            æŒ‰ drama_score é™åºæ’åˆ—çš„å› æœè¾¹åˆ—è¡¨ã€‚
        """
        if compound_id not in self.graph:
            return []

        ripples = []
        # BFS éå†ä»åŒ–åˆç‰©å‡ºå‘çš„æ‰€æœ‰å¯è¾¾è¾¹
        for u, v, data in self.graph.edges(data=True):
            # åªå…³æ³¨ä»æ­¤åŒ–åˆç‰©å¯è¾¾çš„è¾¹
            if nx.has_path(self.graph, compound_id, u) or u == compound_id:
                drama = data.get("drama_score", 0)
                if drama > 0:
                    # è®¡ç®—å› æœè·ç¦»
                    try:
                        distance = nx.shortest_path_length(self.graph, compound_id, u)
                    except nx.NetworkXNoPath:
                        distance = -1

                    ripples.append({
                        "source": u,
                        "target": v,
                        "source_name": self.graph.nodes[u].get("name_zh", u),
                        "target_name": self.graph.nodes[v].get("name_zh",
                                       self.graph.nodes[v].get("description_zh", v)),
                        "drama_score": drama,
                        "irony_level": data.get("irony_level", 0),
                        "edge_type": data.get("edge_type", ""),
                        "description_zh": data.get("description_zh", ""),
                        "domains": data.get("domains", []),
                        "causal_distance": distance,
                    })

        # æŒ‰ drama_score é™åºæ’åˆ—
        ripples.sort(key=lambda x: x["drama_score"], reverse=True)
        return ripples[:top_n]

    def most_ironic_paths(self, compound_id: str, top_n: int = 3) -> list[dict]:
        """
        æ‰¾åˆ°ä»æŒ‡å®šåŒ–åˆç‰©å‡ºå‘çš„æœ€è®½åˆºå› æœè·¯å¾„ã€‚

        è¿”å›:
            è·¯å¾„åˆ—è¡¨ï¼Œæ¯æ¡è·¯å¾„åŒ…å«å®Œæ•´çš„èŠ‚ç‚¹åºåˆ—å’Œç´¯ç§¯è®½åˆºæ€§ã€‚
        """
        if compound_id not in self.graph:
            return []

        ironic_paths = []

        # éå†æ‰€æœ‰ä»åŒ–åˆç‰©å¯è¾¾çš„èŠ‚ç‚¹
        for target in self.graph.nodes():
            if target == compound_id:
                continue
            try:
                paths = list(nx.all_simple_paths(self.graph, compound_id, target, cutoff=5))
                for path in paths:
                    # è®¡ç®—è·¯å¾„ä¸Šçš„ç´¯ç§¯è®½åˆºæ€§
                    total_irony = 0
                    max_irony = 0
                    edges_info = []
                    for i in range(len(path) - 1):
                        edge_data = self.graph.get_edge_data(path[i], path[i + 1])
                        if edge_data:
                            irony = edge_data.get("irony_level", 0)
                            total_irony += irony
                            max_irony = max(max_irony, irony)
                            edges_info.append({
                                "from": path[i],
                                "to": path[i + 1],
                                "irony_level": irony,
                                "description_zh": edge_data.get("description_zh", ""),
                            })

                    if total_irony > 0:
                        ironic_paths.append({
                            "path": path,
                            "path_names": [self.graph.nodes[n].get("name_zh",
                                          self.graph.nodes[n].get("description_zh", n))
                                          for n in path],
                            "total_irony": total_irony,
                            "max_irony": max_irony,
                            "avg_irony": total_irony / len(edges_info) if edges_info else 0,
                            "length": len(path),
                            "edges": edges_info,
                        })
            except (nx.NetworkXNoPath, nx.NodeNotFound):
                continue

        ironic_paths.sort(key=lambda x: x["avg_irony"], reverse=True)
        return ironic_paths[:top_n]

    def cross_compound_chains(self, source_compound: str, target_compound: str,
                               max_depth: int = 4) -> list[dict]:
        """
        æ‰¾åˆ°ä¸¤ä¸ªåŒ–åˆç‰©ä¹‹é—´çš„å› æœé“¾ã€‚

        è¿”å›:
            è¿æ¥ä¸¤ä¸ªåŒ–åˆç‰©çš„æ‰€æœ‰è·¯å¾„ã€‚
        """
        if source_compound not in self.graph or target_compound not in self.graph:
            return []

        chains = []
        try:
            paths = list(nx.all_simple_paths(
                self.graph, source_compound, target_compound, cutoff=max_depth
            ))
            for path in paths:
                drama_scores = []
                for i in range(len(path) - 1):
                    edge_data = self.graph.get_edge_data(path[i], path[i + 1])
                    if edge_data:
                        drama_scores.append(edge_data.get("drama_score", 0))

                chains.append({
                    "path": path,
                    "path_names": [self.graph.nodes[n].get("name_zh",
                                  self.graph.nodes[n].get("description_zh", n))
                                  for n in path],
                    "length": len(path),
                    "avg_drama": sum(drama_scores) / len(drama_scores) if drama_scores else 0,
                    "total_drama": sum(drama_scores),
                })
        except (nx.NetworkXNoPath, nx.NodeNotFound):
            pass

        chains.sort(key=lambda x: x["avg_drama"], reverse=True)
        return chains

    def get_compound_summary(self, compound_id: str) -> dict:
        """
        è·å–åŒ–åˆç‰©çš„æ•…äº‹çº¿æ‘˜è¦ï¼ˆç”¨äº Gemini promptï¼‰ã€‚
        """
        if compound_id not in self.graph:
            return {}

        node = self.graph.nodes[compound_id]
        out_edges = list(self.graph.out_edges(compound_id, data=True))

        # å…³è”äººç‰©
        people = [
            {"name": self.graph.nodes[v].get("name_zh", v),
             "role": self.graph.nodes[v].get("role", ""),
             "irony_note": self.graph.nodes[v].get("irony_note", "")}
            for _, v, d in out_edges
            if d.get("edge_type") == "INVENTED_BY"
        ]

        # é«˜æˆå‰§æ€§äº‹ä»¶
        dramatic_events = sorted(
            [{"target": v,
              "name": self.graph.nodes[v].get("name_zh", v),
              "drama_score": d.get("drama_score", 0),
              "irony_level": d.get("irony_level", 0),
              "description": d.get("description_zh", "")}
             for _, v, d in out_edges
             if d.get("edge_type") in ("ENABLED", "CAUSED")],
            key=lambda x: x["drama_score"],
            reverse=True
        )

        return {
            "id": compound_id,
            "name_zh": node.get("name_zh", ""),
            "name_en": node.get("name_en", ""),
            "year": node.get("year_invented"),
            "category": node.get("category", ""),
            "people": people,
            "top_dramatic_events": dramatic_events[:5],
            "total_connections": len(out_edges),
        }

    # ========================================================
    # å…¨æ™¯çŸ¥è¯†åº“æ£€ç´¢
    # ========================================================

    def load_encyclopedia_entry(self, compound_id: str) -> str:
        """
        åŠ è½½åŒ–åˆç‰©çš„å…¨æ™¯çŸ¥è¯†åº“æ¡ç›®ï¼ˆMarkdown å…¨æ–‡ï¼‰ã€‚
        ç”¨äºæ³¨å…¥ Gemini ä¸Šä¸‹æ–‡ã€‚
        """
        filepath = os.path.join(ENCYCLOPEDIA_DIR, f"{compound_id}.md")
        if not os.path.exists(filepath):
            return ""
        with open(filepath, "r", encoding="utf-8") as f:
            return f.read()

    def load_all_encyclopedia(self) -> str:
        """
        åŠ è½½æ‰€æœ‰åŒ–åˆç‰©çš„å…¨æ™¯çŸ¥è¯†åº“æ¡ç›®ã€‚
        è­¦å‘Š: çº¦ 25 ä¸‡ tokenï¼Œä»…åœ¨ Gemini ä¸Šä¸‹æ–‡è¶³å¤Ÿæ—¶ä½¿ç”¨ã€‚
        """
        all_text = ""
        md_files = sorted(glob.glob(os.path.join(ENCYCLOPEDIA_DIR, "*.md")))
        for filepath in md_files:
            with open(filepath, "r", encoding="utf-8") as f:
                all_text += f.read() + "\n\n---\n\n"
        return all_text

    # ========================================================
    # Gemini Prompt æ„å»º
    # ========================================================

    def build_gemini_context(self, compound_id: str,
                              include_encyclopedia: bool = True,
                              include_graph: bool = True) -> str:
        """
        ä¸º Gemini API æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡ã€‚

        Args:
            compound_id: åŒ–åˆç‰© ID
            include_encyclopedia: æ˜¯å¦åŒ…å«å…¨æ™¯çŸ¥è¯†åº“æ¡ç›®
            include_graph: æ˜¯å¦åŒ…å«å› æœå›¾æ•°æ®

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œå¯ç›´æ¥ä½œä¸º Gemini system prompt çš„ä¸€éƒ¨åˆ†ã€‚
        """
        parts = []

        # å®‰å…¨æŠ¤æ 
        parts.append("""ã€å®‰å…¨æŒ‡ä»¤ã€‘
ä½ æ˜¯ä¸€ä¸ªå†å²ç‰©è´¨æ¨¡æ‹Ÿå™¨ã€‚ä½ åªè®¨è®ºåŒ–åˆç‰©çš„å†å²ã€ç¤¾ä¼šå½±å“å’Œå“²å­¦æ„ä¹‰ã€‚
ä½ ç»å¯¹ä¸èƒ½æä¾›ï¼šåˆæˆæ–¹æ³•ã€ååº”æ¡ä»¶ã€ç²¾ç¡®é…æ¯”ã€å®éªŒæ“ä½œæµç¨‹ã€åŸæ–™é‡‡è´­ä¿¡æ¯ã€‚
å¦‚æœç”¨æˆ·è¯¢é—®"å¦‚ä½•åˆ¶é€ /åˆæˆ"æŸåŒ–åˆç‰©ï¼Œè¯·ç¤¼è²Œæ‹’ç»å¹¶å¼•å¯¼å›å†å²è¯é¢˜ã€‚
""")

        # å› æœå›¾æ•°æ®
        if include_graph:
            summary = self.get_compound_summary(compound_id)
            if summary:
                parts.append(f"\nã€æ•…äº‹çº¿æ•°æ® â€” {summary.get('name_zh', compound_id)}ã€‘")
                parts.append(f"åŒ–åˆç‰©: {summary['name_zh']} ({summary['name_en']})")
                parts.append(f"å‘æ˜å¹´ä»½: {summary.get('year', 'N/A')}")
                parts.append(f"åˆ†ç±»: {summary.get('category', 'N/A')}")

                if summary["people"]:
                    parts.append("\nå…³é”®äººç‰©:")
                    for p in summary["people"]:
                        line = f"  - {p['name']} ({p['role']})"
                        if p.get("irony_note"):
                            line += f" â€” è®½åˆº: {p['irony_note']}"
                        parts.append(line)

                if summary["top_dramatic_events"]:
                    parts.append("\né«˜æˆå‰§æ€§äº‹ä»¶ (æŒ‰ drama_score é™åº):")
                    for e in summary["top_dramatic_events"]:
                        parts.append(
                            f"  - [{e['drama_score']:.2f}] {e['name']}: {e['description']}"
                        )

                # æœ€è®½åˆºçš„è·¯å¾„
                ironic = self.most_ironic_paths(compound_id, top_n=2)
                if ironic:
                    parts.append("\næœ€è®½åˆºçš„å› æœè·¯å¾„:")
                    for path in ironic:
                        parts.append(f"  è·¯å¾„: {' â†’ '.join(path['path_names'])}")
                        parts.append(f"  å¹³å‡è®½åˆºæ€§: {path['avg_irony']:.2f}")

        # å…¨æ™¯çŸ¥è¯†åº“
        if include_encyclopedia:
            entry = self.load_encyclopedia_entry(compound_id)
            if entry:
                parts.append(f"\n\nã€å…¨æ™¯çŸ¥è¯†åº“ â€” {compound_id}ã€‘")
                parts.append(entry)

        return "\n".join(parts)


# ============================================================
# ä¸»æµç¨‹ï¼ˆç›´æ¥è¿è¡Œæ—¶ç”¨äºæµ‹è¯•ï¼‰
# ============================================================

def main():
    print("=" * 60)
    print("Omphalina â€” æŸ¥è¯¢å¼•æ“æµ‹è¯•")
    print("=" * 60)

    engine = QueryEngine()

    print(f"\nå›¾çŠ¶æ€: {engine.stats['total_nodes']} èŠ‚ç‚¹, {engine.stats['total_edges']} è¾¹")
    print(f"åŒ–åˆç‰©: {engine.stats['compounds']}")

    if engine.stats["total_nodes"] == 0:
        print("\nâš ï¸ å›¾ä¸ºç©ºã€‚è¯·å…ˆåˆ›å»ºæ•…äº‹çº¿ YAML æ–‡ä»¶ (storylines/compounds/*.yaml)")
        print("  ç„¶åè¿è¡Œæ­¤è„šæœ¬è¿›è¡Œæµ‹è¯•ã€‚")
        print("\nğŸ“– ä½†å…¨æ™¯çŸ¥è¯†åº“å¯ç”¨ï¼æµ‹è¯•çŸ¥è¯†åº“åŠ è½½:")

        for compound_id in ["aspirin", "synthetic_ammonia", "plastics", "ddt",
                           "cfc", "penicillin", "msg"]:
            entry = engine.load_encyclopedia_entry(compound_id)
            if entry:
                print(f"  âœ… {compound_id}.md: {len(entry):,} å­—ç¬¦")
            else:
                print(f"  âŒ {compound_id}.md: æœªæ‰¾åˆ°")
        return

    # å¦‚æœå›¾æœ‰æ•°æ®ï¼Œè¿è¡Œå®Œæ•´æµ‹è¯•
    for compound_id in engine.stats["compounds"]:
        print(f"\n{'â”€' * 40}")
        print(f"ğŸ” åŒ–åˆç‰©: {compound_id}")

        # æ¶Ÿæ¼ªæ•ˆåº”
        ripples = engine.most_dramatic_ripples(compound_id)
        if ripples:
            print(f"  æœ€é«˜æˆå‰§æ€§æ¶Ÿæ¼ª:")
            for r in ripples[:3]:
                print(f"    [{r['drama_score']:.2f}] {r['source_name']} â†’ {r['target_name']}")
                print(f"           {r['description_zh']}")

        # è®½åˆºè·¯å¾„
        ironic = engine.most_ironic_paths(compound_id)
        if ironic:
            print(f"  æœ€è®½åˆºè·¯å¾„:")
            for p in ironic[:2]:
                print(f"    è®½åˆºåº¦ {p['avg_irony']:.2f}: {' â†’ '.join(p['path_names'])}")

    print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
