#!/usr/bin/env python3
"""
Omphalina çŸ¥è¯†åº“ â€” å› æœå›¾æ„å»ºå™¨

è¯»å– storylines/compounds/*.yaml å’Œ cross_connections.yamlï¼Œ
æ„å»º NetworkX æœ‰å‘å›¾ (DiGraph)ï¼Œä¾› query_engine.py ä½¿ç”¨ã€‚

ç”¨æ³•:
    from graph_builder import build_graph, load_graph_from_storylines
    G = load_graph_from_storylines()
"""

import os
import glob
import yaml
import networkx as nx
from typing import Any

# ============================================================
# é…ç½®
# ============================================================

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
STORYLINES_DIR = os.path.join(BASE_DIR, "storylines", "compounds")
CROSS_CONNECTIONS_PATH = os.path.join(BASE_DIR, "storylines", "cross_connections.yaml")


# ============================================================
# å›¾æ„å»º
# ============================================================

def load_yaml(filepath: str) -> dict:
    """å®‰å…¨åŠ è½½ YAML æ–‡ä»¶"""
    with open(filepath, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def add_compound_to_graph(G: nx.DiGraph, data: dict) -> None:
    """
    å°†ä¸€ä¸ªåŒ–åˆç‰©çš„æ•…äº‹çº¿æ•°æ®æ·»åŠ åˆ°å›¾ä¸­ã€‚

    æœŸæœ›çš„ YAML ç»“æ„:
    compound:
      id: aspirin
      name_zh: é˜¿å¸åŒ¹æ—
      ...
      people: [...]
      events: [...]
      consequences: [...]
      causal_chains: [...]
    """
    compound = data.get("compound", {})
    compound_id = compound.get("id")
    if not compound_id:
        return

    # æ·»åŠ åŒ–åˆç‰©èŠ‚ç‚¹
    G.add_node(compound_id,
               node_type="Compound",
               name_zh=compound.get("name_zh", ""),
               name_en=compound.get("name_en", ""),
               aliases_zh=compound.get("aliases_zh", []),
               category=compound.get("category", ""),
               year_invented=compound.get("year_invented"),
               formula=compound.get("formula", ""),
               safety_note=compound.get("safety_note", ""))

    # æ·»åŠ äººç‰©èŠ‚ç‚¹ + INVENTED_BY è¾¹
    for person in compound.get("people", []):
        person_id = person.get("id")
        if not person_id:
            continue
        G.add_node(person_id,
                   node_type="Person",
                   name_zh=person.get("name_zh", ""),
                   name_en=person.get("name_en", ""),
                   role=person.get("role", ""),
                   birth_year=person.get("birth_year"),
                   death_year=person.get("death_year"),
                   nationality=person.get("nationality", ""),
                   nobel_year=person.get("nobel_year"),
                   irony_note=person.get("irony_note", ""))

        G.add_edge(compound_id, person_id,
                   edge_type="INVENTED_BY",
                   year=person.get("year"),
                   context=person.get("context", ""))

    # æ·»åŠ äº‹ä»¶èŠ‚ç‚¹
    for event in compound.get("events", []):
        event_id = event.get("id")
        if not event_id:
            continue
        G.add_node(event_id,
                   node_type="Event",
                   name_zh=event.get("name_zh", ""),
                   name_en=event.get("name_en", ""),
                   year=event.get("year"),
                   end_year=event.get("end_year"),
                   domain=event.get("domain", ""),
                   location=event.get("location", ""),
                   scale=event.get("scale", ""),
                   quote=event.get("quote", ""),
                   source_ref=event.get("source_ref", ""))

    # æ·»åŠ åæœèŠ‚ç‚¹
    for consequence in compound.get("consequences", []):
        cons_id = consequence.get("id")
        if not cons_id:
            continue
        G.add_node(cons_id,
                   node_type="Consequence",
                   description_zh=consequence.get("description_zh", ""),
                   description_en=consequence.get("description_en", ""),
                   type=consequence.get("type", ""),
                   domain=consequence.get("domain", ""),
                   scale=consequence.get("scale", ""),
                   ongoing=consequence.get("ongoing", False),
                   quantifier=consequence.get("quantifier", ""))

    # æ·»åŠ å› æœé“¾ï¼ˆè¾¹ï¼‰
    for chain in compound.get("causal_chains", []):
        source = chain.get("source", compound_id)
        target = chain.get("target")
        if not target:
            continue

        edge_type = chain.get("type", "ENABLED")
        G.add_edge(source, target,
                   edge_type=edge_type,
                   drama_score=chain.get("drama_score", 0.5),
                   irony_level=chain.get("irony_level", 0.5),
                   time_lag_years=chain.get("time_lag_years"),
                   domains=chain.get("domains", []),
                   description_zh=chain.get("description_zh", ""),
                   description_en=chain.get("description_en", ""))


def add_cross_connections(G: nx.DiGraph, data: dict) -> None:
    """æ·»åŠ è·¨åŒ–åˆç‰©è¿æ¥"""
    for conn in data.get("connections", []):
        source = conn.get("source_compound")
        target = conn.get("target_compound")
        if not source or not target:
            continue

        G.add_edge(source, target,
                   edge_type="CROSS_CONNECTION",
                   connection_type=conn.get("connection_type", ""),
                   relationship_zh=conn.get("relationship_zh", ""),
                   relationship_en=conn.get("relationship_en", ""),
                   drama_score=conn.get("drama_score", 0.5),
                   bidirectional=conn.get("bidirectional", True))

        # å¦‚æœæ˜¯åŒå‘è¿æ¥ï¼Œæ·»åŠ åå‘è¾¹
        if conn.get("bidirectional", True):
            G.add_edge(target, source,
                       edge_type="CROSS_CONNECTION",
                       connection_type=conn.get("connection_type", ""),
                       relationship_zh=conn.get("relationship_zh", ""),
                       relationship_en=conn.get("relationship_en", ""),
                       drama_score=conn.get("drama_score", 0.5),
                       bidirectional=True)


# ============================================================
# å…¬å…±æ¥å£
# ============================================================

def load_graph_from_storylines() -> nx.DiGraph:
    """
    ä» storylines/ ç›®å½•åŠ è½½æ‰€æœ‰æ•°æ®ï¼Œæ„å»ºå¹¶è¿”å›å®Œæ•´çš„å› æœå›¾ã€‚
    è¿™æ˜¯å¤–éƒ¨æ¨¡å—ï¼ˆå¦‚ query_engine.pyï¼‰è°ƒç”¨çš„ä¸»å…¥å£ã€‚
    """
    G = nx.DiGraph()

    # åŠ è½½æ‰€æœ‰åŒ–åˆç‰©æ•…äº‹çº¿
    yaml_files = glob.glob(os.path.join(STORYLINES_DIR, "*.yaml"))
    for filepath in sorted(yaml_files):
        data = load_yaml(filepath)
        add_compound_to_graph(G, data)

    # åŠ è½½è·¨åŒ–åˆç‰©è¿æ¥
    if os.path.exists(CROSS_CONNECTIONS_PATH):
        cross_data = load_yaml(CROSS_CONNECTIONS_PATH)
        add_cross_connections(G, cross_data)

    return G


def get_graph_stats(G: nx.DiGraph) -> dict:
    """è·å–å›¾çš„ç»Ÿè®¡ä¿¡æ¯"""
    node_types = {}
    for _, attrs in G.nodes(data=True):
        nt = attrs.get("node_type", "Unknown")
        node_types[nt] = node_types.get(nt, 0) + 1

    edge_types = {}
    for _, _, attrs in G.edges(data=True):
        et = attrs.get("edge_type", "Unknown")
        edge_types[et] = edge_types.get(et, 0) + 1

    # é«˜æˆå‰§æ€§è¾¹
    high_drama = [(u, v, d) for u, v, d in G.edges(data=True)
                  if d.get("drama_score", 0) >= 0.9]

    # é«˜è®½åˆºæ€§è¾¹
    high_irony = [(u, v, d) for u, v, d in G.edges(data=True)
                  if d.get("irony_level", 0) >= 0.9]

    return {
        "total_nodes": G.number_of_nodes(),
        "total_edges": G.number_of_edges(),
        "node_types": node_types,
        "edge_types": edge_types,
        "high_drama_edges": len(high_drama),
        "high_irony_edges": len(high_irony),
        "connected_components": nx.number_weakly_connected_components(G),
        "compounds": [n for n, d in G.nodes(data=True) if d.get("node_type") == "Compound"],
    }


def export_graph_json(G: nx.DiGraph, filepath: str) -> None:
    """å°†å›¾å¯¼å‡ºä¸º JSON æ ¼å¼ï¼ˆå¯ç”¨äºå‰ç«¯å¯è§†åŒ–ï¼‰"""
    import json
    from networkx.readwrite import json_graph
    data = json_graph.node_link_data(G)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# ============================================================
# ä¸»æµç¨‹ï¼ˆç›´æ¥è¿è¡Œæ—¶ç”¨äºéªŒè¯ï¼‰
# ============================================================

def main():
    print("=" * 60)
    print("Omphalina â€” å› æœå›¾æ„å»ºä¸éªŒè¯")
    print("=" * 60)

    G = load_graph_from_storylines()
    stats = get_graph_stats(G)

    print(f"\nğŸ“Š å›¾ç»Ÿè®¡:")
    print(f"  èŠ‚ç‚¹æ€»æ•°: {stats['total_nodes']}")
    print(f"  è¾¹æ€»æ•°:   {stats['total_edges']}")
    print(f"\n  èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ:")
    for nt, count in sorted(stats["node_types"].items()):
        print(f"    {nt}: {count}")
    print(f"\n  è¾¹ç±»å‹åˆ†å¸ƒ:")
    for et, count in sorted(stats["edge_types"].items()):
        print(f"    {et}: {count}")
    print(f"\n  é«˜æˆå‰§æ€§è¾¹ (â‰¥0.9): {stats['high_drama_edges']}")
    print(f"  é«˜è®½åˆºæ€§è¾¹ (â‰¥0.9): {stats['high_irony_edges']}")
    print(f"  å¼±è¿é€šåˆ†é‡æ•°: {stats['connected_components']}")
    print(f"  åŒ–åˆç‰©åˆ—è¡¨: {stats['compounds']}")

    if stats["total_nodes"] == 0:
        print("\nâš ï¸ å›¾ä¸ºç©ºï¼è¯·å…ˆåœ¨ storylines/compounds/ ä¸­åˆ›å»ºæ•…äº‹çº¿ YAML æ–‡ä»¶ã€‚")
    else:
        # å¯¼å‡º JSON
        export_path = os.path.join(BASE_DIR, "storylines", "graph_export.json")
        export_graph_json(G, export_path)
        print(f"\n  å›¾å·²å¯¼å‡º: {export_path}")

    print("=" * 60)


if __name__ == "__main__":
    main()
